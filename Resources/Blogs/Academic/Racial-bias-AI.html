<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script type="module" src="../../../Menu/menu.js"></script>
    <link rel="stylesheet" href="../../CSS/main.css">
    <link rel="stylesheet" href="../../CSS/menu.css">
    <link rel="stylesheet" href="../../CSS/accessibility.css">
    <title>Bias in AI</title>
</head>
<body>
    <nav></nav>

    <h1>Racial bias in Artificial Intelligence</h1>
    <article>
        <p>
            Artificial intelligence (AI) is the future, it is wide-spread and it is being incorporated into every aspect of our lives.[1] This gives AI a potential
            for large scale power in our current and future world. With such power comes the need for these systems to be ethically and socially just. This is
            currently not the case. There is a presence of racial bias in current AI systems. 
        </p>
        <p>
            AI systems are wide-spread and thus so are its racial bias. In large scale surveillance systems for example, racial bias has the potential
            to unethically target people of specific races. In more uneccessary cases these systems stereotype and discrminate. For example in the British 
            passport system a case occured in which a black female photograph was flagged as it indicated that her mouth was open, when in fact it was not. 
            <a href="https://twitter.com/sophieodira/status/1232365662389112832">Here</a> is the tweet in which this was brought to light. 
            There is also another case dealing with the popular social media app, Tiktok. In <a href="https://twitter.com/MarcFaddoul/status/1232014908536938498">this</a> tweet
            the racial bias in Tiktok's suggestion algorithm is blantantly exoposed. This begs the question, surely this algorithm has to be based off
            something else than solely people's skin colour?
        </p>
        <p>
            We have established that racial bias is present in AI. Now let us look into why this is the case. At the end of the day
            AI is a robot, a system designed by people and its bias stems from the training it had received and ultimately the people who made it. 
            The system as a whole is only as good as the data that is given to them [2]. IBM for example has openly admited that AI systems around the world 
            are being trained with unrepresentative data sets [2] and thus this racial bias will continue to be a problem. As this racial bias stems
            from the information it is given, the problem can be fixed. The inherent racial bias in AI can be removed. But will it?

        </p>
        <p>
            Let us look into reasons why this is not happening. Firstly, we have to keep in mind that people are by nature biased in some way. The
            very idea of being subjective is biased. Therefore any data set has a high chance of being somewhat biased. However, this is not a 
            justifiable and acceptable reason for the current racial bias in AI. Larger and more representative data sets can be used. More needs to be done 
            to recognise and fix these problems in current AI. Next, the root of all evil, money.
        </p>
        <p>
            In order to allow and use more representative data sets, more financial backing is required. From a purely financial perspective,
            the people who are paying to develop AI will most often come to the same conclusion: they do not want to spend extra resources to gather
            a large enough and well represented sample. One of the reasons supporting this is that the sole idea of, what is a well represented sample?
            Is this even possible? From an investors view, they will be reluctant to invest more money into an idea that can't be explicitly defined.
        </p>
        <p>
            Let us now look into the effects of correcting the racial bias in AI.
            Does the task of correcting and preventing racial bias in AI have the potential to create more injustices? For example from a financial
            perspective- Let us assume it will cost around 40% more to alleviate and fix 60% of the current racial bias in a particular AI system. The company
            decided for this and invests the respective resoures. Now the question is, who decides what racial bias will be fixed. All of the present 
            bias in the system can not be fixed as there is not enough financial resources to allow this, only 60% can be. Who decides what will be fixed
            and what will not. Will the decision of what remaining 40% is, be just as much of an injustice as the original problem was?
        </p>
        <p>
            Recognising and removing racial bias in AI is a complex task that is hoped to be addressed and removed in future. Have a look at 
            <a href="https://www.youtube.com/watch?v=KCefAIO_AD4&feature=youtu.be">this</a> video, it is in interesting take into racial bias present in software.
        </p>

        <p>
            <h3>References</h3>

            <ul>
                <li>[1] Builtin. 2016. Artificial Intelligence. [ONLINE] Available <a href="https://builtin.com/artificial-intelligence/artificial-intelligence-future">here</a> [Accessed 21 May 2020].</li>
                <li>[2] IBM. 2018. AI and Bias. [ONLINE] Available <a href="https://www.research.ibm.com/5-in-5/ai-and-bias/">here</a> [Accessed 21 May 2020]</li>

            </ul>
        </p>
    </article>


    <section class="return">
        <a href="./index.html">Return</a>
    </section>
</body>
<footer></footer>
</html>